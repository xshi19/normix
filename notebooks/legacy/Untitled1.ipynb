{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import solve_triangular\n",
    "from scipy.special import kv\n",
    "\n",
    "sys.path.append('/Users/xiangshi/Documents/GitHub/normix/')\n",
    "\n",
    "from normix.gig import GIG\n",
    "from normix.func import logkv, kvratio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GH(object):\n",
    "    \"\"\"\n",
    "    Generalized Hyperbolic (GH)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu, gamma, sigma, lam, chi, psi):\n",
    "        \n",
    "        self.mu = mu\n",
    "        self.gamma = gamma\n",
    "        self.sigma = sigma\n",
    "        self.lam = lam\n",
    "        self.chi = chi\n",
    "        self.psi = psi\n",
    "        self.dim = len(mu)\n",
    "        \n",
    "    def pdf(self, x):\n",
    "        l = np.linalg.cholesky(self.sigma)\n",
    "        z = solve_triangular(l, (x-self.mu).T, lower=True)\n",
    "        gamma = solve_triangular(l, self.gamma)\n",
    "        lam = self.lam-self.dim/2\n",
    "        chi = self.chi+np.sum(z**2, axis=0)\n",
    "        psi = self.psi+np.dot(gamma, gamma)\n",
    "\n",
    "        c = (self.psi/self.chi)**(self.lam/2)/(2*np.pi)**(self.dim/2)/ \\\n",
    "            np.prod(np.diag(l))/kv(self.lam, np.sqrt(self.chi*self.psi) + 0.0j).real\n",
    "        p = c*kv(lam, np.sqrt(chi*psi))*np.exp(np.dot(z.T, gamma))* \\\n",
    "            np.sqrt(psi/chi)**(self.dim/2-self.lam);\n",
    "        return p\n",
    "    \n",
    "    def llh(self, x):\n",
    "        l = np.linalg.cholesky(self.sigma)\n",
    "        z = solve_triangular(l, (x-self.mu).T, lower=True)\n",
    "        gamma = solve_triangular(l, self.gamma)\n",
    "        lam = self.lam-self.dim/2\n",
    "        chi = self.chi+np.sum(z**2, axis=0)\n",
    "        psi = self.psi+np.dot(gamma, gamma)\n",
    "        \n",
    "        delta = np.sqrt(chi/psi)\n",
    "        eta = np.sqrt(chi*psi)\n",
    "        \n",
    "        llh = self.lam/2*np.log(self.psi/self.chi) \\\n",
    "            - logkv(self.lam, np.sqrt(self.chi*self.psi)) \\\n",
    "            + logkv(lam, eta) + np.dot(z.T, gamma) + lam*np.log(delta)\n",
    "        return llh, lam, delta, eta\n",
    "        \n",
    "    \n",
    "    def mean(self):\n",
    "        return self.mu+self.gamma*GIG(self.lam, self.chi, self.psi).mean()\n",
    "    \n",
    "    def cov(self):\n",
    "        gig = GIG(self.lam, self.chi, self.psi)\n",
    "        return self.sigma*gig.mean() + np.outer(self.gamma, self.gamma)*gig.var()\n",
    "    \n",
    "    def fit_em(self, x, max_iter=100, fix_tail=False, eps=1e-5, reg='|sigma|=1', diff=1e-5, disp=True):\n",
    "        if self.dim != x.shape[1]:\n",
    "            raise ValueError('x dimension must be (, {})'.format(self.dim))\n",
    "            \n",
    "        suff_stats = [0]*6\n",
    "        suff_stats[3] = np.mean(x, axis=0)\n",
    "        \n",
    "        llh_last = 0\n",
    "        for i in range(max_iter):\n",
    "            # self.regulate(reg)\n",
    "            llh, lam, delta, eta = self.llh(x)\n",
    "                \n",
    "            if i>0:\n",
    "                if disp:\n",
    "                    print('iter=%s, llh=%.5f, change=%.5f'%(i, llh, llh-llh_last))\n",
    "                \n",
    "                if np.abs(llh-llh_last)<eps:\n",
    "                    if disp:\n",
    "                        print('success')\n",
    "                    return True\n",
    "            llh_last = llh\n",
    "        \n",
    "            # E-step\n",
    "            a = kvratio(lam-1, lam, eta)/delta\n",
    "            b = kvratio(lam+1, lam, eta)*delta\n",
    "            c = (kvratio(lam+diff, lam, eta)-kvratio(lam-diff, lam, eta))/(2*diff)+np.log(delta)\n",
    "\n",
    "            suff_stats[0] = np.mean(a)\n",
    "            suff_stats[1] = np.mean(b)\n",
    "            suff_stats[2] = np.mean(c)\n",
    "            suff_stats[4] = np.mean(x.T*a, axis=1)\n",
    "            suff_stats[5] = np.dot((x.T*a)/x.shape[0], x)\n",
    "            \n",
    "            if not fix_tail:\n",
    "                gig = GIG(gh.lam, gh.chi, gh.psi)\n",
    "                res = gig.suffstats2param(suff_stats[0], suff_stats[1], suff_stats[2])\n",
    "                if res.success:\n",
    "                    self.lam = gig.lam\n",
    "                    self.chi = gig.chi\n",
    "                    self.psi = gig.psi\n",
    "                \n",
    "            self.mu = (suff_stats[3]-suff_stats[1]*suff_stats[4])/(1-suff_stats[0]*suff_stats[1])\n",
    "            self.gamma = (suff_stats[4]-suff_stats[0]*suff_stats[3])/(1-suff_stats[0]*suff_stats[1])\n",
    "            self.sigma = -np.outer(suff_stats[4], self.mu)\n",
    "            self.sigma = self.sigma + self.sigma.T + suff_stats[5] \\\n",
    "                + suff_stats[0]*np.outer(self.mu, self.mu) \\\n",
    "                - suff_stats[1]*np.outer(self.gamma, self.gamma)\n",
    "            # self.sigma = np.maximum(self.sigma, self.sigma.T)\n",
    "            \n",
    "        if disp:\n",
    "            print('fail to converge')\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def rvs(self, n, n_grids=int(1e5)):\n",
    "        t = GIG(self.lam, self.chi, self.psi).rvs(n, n_grids)\n",
    "        z = np.random.multivariate_normal(np.zeros(self.dim), self.sigma, n)\n",
    "        x = (np.outer(self.gamma, t) + z.T*np.sqrt(t)).T + mu\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def regulate(self, method='|sigma|=1'):\n",
    "        \"\"\" GH parameterization (mu, gamma Sigma, lambda, chi, psi) is not unique, so regulation is needed.\n",
    "        \"\"\"\n",
    "        if method=='chi=1':\n",
    "            self.gamma = self.gamma*self.chi\n",
    "            self.sigma = self.sigma*self.chi\n",
    "            self.psi = self.psi*self.chi\n",
    "            self.chi = 1.0\n",
    "        elif method=='psi=1':\n",
    "            self.gamma = self.gamma/self.psi\n",
    "            self.sigma = self.sigma/self.psi\n",
    "            self.chi = self.chi*self.psi\n",
    "            self.psi = 1.0\n",
    "        elif method=='chi=psi':\n",
    "            self.gamma = self.gamma*np.sqrt(self.chi/self.psi)\n",
    "            self.sigma = self.sigma*np.sqrt(self.chi/self.psi)\n",
    "            self.chi = np.sqrt(self.chi*self.psi)\n",
    "            self.psi = self.chi\n",
    "        elif method=='|sigma|=1':\n",
    "            _, logd = np.linalg.slogdet(self.sigma)\n",
    "            d = np.exp(logd/self.dim)\n",
    "            self.gamma = self.gamma/d\n",
    "            self.sigma = self.sigma/d\n",
    "            self.chi = self.chi*d\n",
    "            self.psi = self.psi/d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.random.randn(10)\n",
    "sigma = np.cov(np.random.randn(10, 20))\n",
    "gamma = np.random.randn(10)\n",
    "lam=0.9\n",
    "chi=0.3\n",
    "psi=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0.65634476,  1.51842634, -0.63371085])\n",
    "sigma= np.array([[0.35646818, 0.10212985, 0.05799233],\n",
    "       [0.10212985, 0.98229971, 0.15375874],\n",
    "       [0.05799233, 0.15375874, 1.41077451]])\n",
    "gamma = np.array([ 2.05705176, -0.04197259,  0.34341511])\n",
    "lam=0.9\n",
    "chi=0.3\n",
    "psi=1.0\n",
    "\n",
    "mu0 = np.zeros(3)\n",
    "sigma0 = np.eye(3)\n",
    "gamma0 = np.zeros(3)\n",
    "lam0 = 1.0\n",
    "chi0 = 1.0\n",
    "psi0 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6949953239248218e-16 4.096647724127068e-16\n",
      "2.102382951329647e-17 2.0234082797393442e-16\n",
      "0.0 0.0\n",
      "2.102382951329647e-17 3.54598817343108e-17\n"
     ]
    }
   ],
   "source": [
    "gh = GH(mu, gamma, sigma, lam, chi, psi)\n",
    "m = gh.mean()\n",
    "c = gh.cov()\n",
    "for method in ['|sigma|=1', 'chi=1', 'psi=1', 'chi=psi']:\n",
    "    gh = GH(mu, gamma, sigma, lam, chi, psi)\n",
    "    gh.regulate(method)\n",
    "    print(np.linalg.norm(gh.mean()-m)/np.linalg.norm(m), \n",
    "          np.linalg.norm(gh.cov()-c)/np.linalg.norm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027160269672164564 0.07101347388016566\n"
     ]
    }
   ],
   "source": [
    "gh = GH(mu, gamma, sigma, lam, chi, psi)\n",
    "gh.regulate()\n",
    "x = gh.rvs(1000)\n",
    "print(np.linalg.norm(np.mean(x, axis=0)-m)/np.linalg.norm(m), \n",
    "      np.linalg.norm(np.cov(x.T)-c)/np.linalg.norm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 1.74953772,  1.37746568, -1.54835839],\n",
    "       [ 3.76765938,  1.54792901, -0.36846954],\n",
    "       [ 5.70719392,  0.82978642, -2.07754969],\n",
    "       [ 1.95051383,  0.62586649, -0.66932423],\n",
    "       [ 7.93513039,  0.54582224,  0.90509363],\n",
    "       [11.64517463, -0.26257948,  7.62055921],\n",
    "       [ 0.47822655,  2.261273  , -0.68519925],\n",
    "       [14.36924369,  2.9331593 , -0.39317326],\n",
    "       [ 3.06647501,  0.94545944,  0.87562929],\n",
    "       [ 2.36628983,  1.99396013, -0.60114535]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_fit = GH(mu0, gamma0, sigma0, lam0, chi0, psi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "suff_stats = [0]*6\n",
    "suff_stats[3] = np.mean(x, axis=0)\n",
    "llh_last = 0\n",
    "i = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh, lam, delta, eta = gh_fit.llh(x)\n",
    "\n",
    "# E-step\n",
    "a = kvratio(lam-1, lam, eta)/delta\n",
    "b = kvratio(lam+1, lam, eta)*delta\n",
    "c = (kvratio(lam+diff, lam, eta)-kvratio(lam-diff, lam, eta))/(2*diff)+np.log(delta)\n",
    "\n",
    "suff_stats[0] = np.mean(a)\n",
    "suff_stats[1] = np.mean(b)\n",
    "suff_stats[2] = np.mean(c)\n",
    "suff_stats[4] = np.mean(x.T*a, axis=1)\n",
    "suff_stats[5] = np.dot((x.T*a)/x.shape[0], x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "gig = GIG(gh.lam, gh.chi, gh.psi)\n",
    "res = gig.suffstats2param(suff_stats[0], suff_stats[1], suff_stats[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0918306 , 4.65295278, 0.26519496])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'self' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-100969edbe9c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m+\u001b[0m \u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mouter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'self' is not defined"
     ]
    }
   ],
   "source": [
    "self.mu = (suff_stats[3]-suff_stats[1]*suff_stats[4])/(1-suff_stats[0]*suff_stats[1])\n",
    "self.gamma = (suff_stats[4]-suff_stats[0]*suff_stats[3])/(1-suff_stats[0]*suff_stats[1])\n",
    "self.sigma = -np.outer(suff_stats[4], gh_fit.mu)\n",
    "gh_fit.sigma = gh_fit.sigma + gh_fit.sigma.T + suff_stats[5] \\\n",
    "    + suff_stats[0]*np.outer(gh_fit.mu, gh_fit.mu) \\\n",
    "    - suff_stats[1]*np.outer(gh_fit.gamma, gh_fit.gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.00213049e-06, -2.14346395e-06, -1.49743216e-06, -3.56217451e-06,\n",
       "       -1.17081863e-06, -6.92563171e-07, -3.28326966e-06, -6.58354477e-07,\n",
       "       -2.55025381e-06, -2.66455083e-06])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(kvratio(lam+diff, lam, eta)-kvratio(lam-diff, lam, eta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.89062409,  4.21035761,  6.21102412,  2.37575419,  8.067429  ,\n",
       "       13.95535606,  2.60989544, 14.70486902,  3.47331098,  3.30705009])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34594605, 1.23750952, 1.16100404, 1.42091897, 1.12395523,\n",
       "       1.07165708, 1.38315711, 1.06800469, 1.28790972, 1.30238429])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv(lam-1, eta)/kv(lam, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1, llh=-4.07511, change=5.72913\n",
      "iter=2, llh=-0.59984, change=3.47526\n",
      "iter=3, llh=-2.11217, change=-1.51233\n",
      "iter=4, llh=-2.57087, change=-0.45870\n",
      "iter=5, llh=-2.87619, change=-0.30532\n",
      "iter=6, llh=-3.00005, change=-0.12386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7, llh=-3.15745, change=-0.15740\n",
      "iter=8, llh=-3.19400, change=-0.03656\n",
      "iter=9, llh=-3.29609, change=-0.10209\n",
      "iter=10, llh=-3.34145, change=-0.04536\n",
      "iter=11, llh=-3.39780, change=-0.05635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=12, llh=-3.42807, change=-0.03026\n",
      "iter=13, llh=-3.48110, change=-0.05303\n",
      "iter=14, llh=-3.49623, change=-0.01514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=15, llh=-3.51029, change=-0.01406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=16, llh=-3.57696, change=-0.06667\n",
      "iter=17, llh=-3.59409, change=-0.01713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=18, llh=-3.61947, change=-0.02537\n",
      "iter=19, llh=-3.64719, change=-0.02773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=20, llh=-3.66577, change=-0.01857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=21, llh=-3.67505, change=-0.00928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=22, llh=-3.69056, change=-0.01551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=23, llh=-3.71613, change=-0.02557\n",
      "iter=24, llh=-3.71479, change=0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=25, llh=-3.73685, change=-0.02206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=26, llh=-3.75535, change=-0.01849\n",
      "iter=27, llh=-3.75546, change=-0.00012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=28, llh=-3.80121, change=-0.04574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=29, llh=-3.78614, change=0.01506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=30, llh=-3.77543, change=0.01071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=31, llh=-3.80587, change=-0.03043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=32, llh=-3.82195, change=-0.01609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=33, llh=-3.82992, change=-0.00796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-0f2b626ee60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgh_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_em\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_tail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-de3c720ebae4>\u001b[0m in \u001b[0;36mfit_em\u001b[0;34m(self, x, max_iter, fix_tail, eps, reg, diff, disp)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfix_tail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mgig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGIG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffstats2param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/normix/normix/gig.py\u001b[0m in \u001b[0;36msuffstats2param\u001b[0;34m(self, s1, s2, s3)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trust-constr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    621\u001b[0m                                             \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                                             callback=callback, **options)\n\u001b[0m\u001b[1;32m    623\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dogleg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         return _minimize_dogleg(fun, x0, args, jac, hess,\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m_minimize_trustregion_constr\u001b[0;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0minitial_barrier_tolerance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0minitial_constr_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_tr_radius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             factorization_method)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# Status 3 occurs when the callback function requests termination,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py\u001b[0m in \u001b[0;36mtr_interior_point\u001b[0;34m(fun, grad, lagr_hess, n_vars, n_ineq, n_eq, constr, jac, x0, fun0, grad0, constr_ineq0, jac_ineq0, constr_eq0, jac_eq0, stop_criteria, enforce_feasibility, xtol, state, initial_barrier_parameter, initial_tolerance, initial_penalty, initial_trust_radius, factorization_method)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mconstr0_subprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac0_subprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_criteria\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_radius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             factorization_method, trust_lb, trust_ub, subprob.scaling)\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/equality_constrained_sqp.py\u001b[0m in \u001b[0;36mequality_constrained_sqp\u001b[0;34m(fun_and_constr, grad_and_jac, lagr_hess, x0, fun0, grad0, constr0, jac0, stop_criteria, state, initial_penalty, initial_trust_radius, factorization_method, trust_lb, trust_ub, scaling)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# Get projections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorization_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;31m# Compute least-square lagrange multipliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/projections.py\u001b[0m in \u001b[0;36mprojections\u001b[0;34m(A, method, orth_tol, max_refin, tol)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AugmentedSystem'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mnull_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_space\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;34m=\u001b[0m \u001b[0maugmented_system_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morth_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_refin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"QRFactorization\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mnull_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_space\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/projections.py\u001b[0m in \u001b[0;36maugmented_system_projections\u001b[0;34m(A, m, n, orth_tol, max_refin, tol)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m\"\"\"Return linear operators for matrix A - ``AugmentedSystem``.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Form augmented system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;31m# LU factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# TODO: Use a symmetric indefinite factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mblock_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mcoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/sparse/dia.py\u001b[0m in \u001b[0;36mtocoo\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moffset_inds\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_offsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gh_fit.fit_em(x, fix_tail=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "k = np.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorial(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_fit.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff = 1e-8\n",
    "reg = '|sigma|=1'\n",
    "\n",
    "suff_stats = [0]*6\n",
    "suff_stats[3] = np.mean(x, axis=0)\n",
    "\n",
    "gh.regulate(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh, lam, delta, eta = gh.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = kvratio(lam-1, lam, eta)\n",
    "\n",
    "suff_stats[0] = np.mean(s)\n",
    "suff_stats[1] = np.mean(kvratio(lam+1, lam, eta))\n",
    "suff_stats[2] = np.mean((kvratio(lam+diff, lam, eta)-kvratio(lam-diff, lam, eta))/(2*diff))\n",
    "suff_stats[4] = np.mean(x.T*s, axis=1)\n",
    "suff_stats[5] = np.dot((x.T*s)/x.shape[0], x)\n",
    "suff_stats[5] = np.maximum(suff_stats[5], suff_stats[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = (S4-S2*S5)/(1-S1*S2);\n",
    "    gamma = (S5-S1*S4)/(1-S1*S2);\n",
    "    Sigma = S6-S5*mu'-mu*S5'+S1*(mu*mu')-S2*(gamma*gamma');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_fit.mu = (suff_stats[3]-suff_stats[1]*suff_stats[4])/(1-suff_stats[0]*suff_stats[1])\n",
    "gh_fit.gamma = (suff_stats[4]-suff_stats[0]*suff_stats[3])/(1-suff_stats[0]*suff_stats[1])\n",
    "gh_fit.sigma = -np.outer(suff_stats[4], gh_fit.mu)\n",
    "gh_fit.sigma = gh_fit.sigma + gh_fit.sigma.T + suff_stats[5] \\\n",
    "    + suff_stats[0]*np.outer(gh_fit.mu, gh_fit.mu) \\\n",
    "    - suff_stats[1]*np.outer(gh_fit.gamma, gh_fit.gamma)\n",
    "# gh_fit.sigma[5] = np.maximum(gh_fit.sigma[5], gh_fit.sigma[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62270148,  1.42936867, -1.12930602])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fit.mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78617701, -0.09383308,  0.14378663],\n",
       "       [-0.09383308,  0.14945062, -0.10842705],\n",
       "       [ 0.14378663, -0.10842705,  0.54143216]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fit.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.75734847, -0.02419753,  0.23219751])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fit.gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gig = GIG(gh.lam, gh.chi, gh.psi)\n",
    "res = gig.suffstats2param(suff_stats[0], suff_stats[1], suff_stats[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update = GH(self.mu, self.gamma, self.sigma, gig.lam, gig.chi, gig.psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update.regulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update.sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(gh_update.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.svd(gh_update.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    gh_univ = GH(mu=gh.mu[[i]], \n",
    "                 sigma=np.array([[np.diag(gh.sigma)[i]]]), \n",
    "                 gamma=gh.gamma[[i]], \n",
    "                 lam=gh.lam, chi=gh.chi, psi=gh.psi)\n",
    "    nbins = 1000\n",
    "    hist, grids = np.histogram(x[:, i], bins=nbins)\n",
    "    dx = grids[1]-grids[0]\n",
    "\n",
    "    xi = (grids[1:]-dx/2).reshape((nbins, 1))\n",
    "    pdf = gh_univ.pdf(xi)*dx\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.step(grids[1:], hist/np.sum(hist))\n",
    "    ax.step(xi, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'iter=%s, llh=%.2f, change='%(1, llh, chg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
