{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import minimize\n",
    "from scipy.linalg import solve_triangular\n",
    "from scipy.special import kv\n",
    "\n",
    "sys.path.append('/Users/xiangshi/Documents/GitHub/pygh/')\n",
    "\n",
    "from pygh.gig import GIG\n",
    "from pygh.func import logkv, kvratio\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe29bdec650>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = 100\n",
    "z = np.linspace(1e-2, 1, 1000)\n",
    "plt.plot(logkv(v, z))\n",
    "plt.plot(np.log(kv(v, z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/Documents/GitHub/pygh/pygh/func.py:7: RuntimeWarning: divide by zero encountered in log\n",
      "  y = np.log(kv(v, z))\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe29c533950>]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = 100\n",
    "z = np.linspace(1e2, 1e3, 1000)\n",
    "plt.plot(logkv(v, z))\n",
    "plt.plot(np.log(kv(v, z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GH(object):\n",
    "    \"\"\"\n",
    "    Generalized Hyperbolic (GH)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mu, gamma, sigma, lam, chi, psi):\n",
    "        \n",
    "        self.mu = mu\n",
    "        self.gamma = gamma\n",
    "        self.sigma = sigma\n",
    "        self.lam = lam\n",
    "        self.chi = chi\n",
    "        self.psi = psi\n",
    "        self.dim = len(mu)\n",
    "        \n",
    "    def pdf(self, x):\n",
    "        l = np.linalg.cholesky(self.sigma)\n",
    "        z = solve_triangular(l, (x-self.mu).T, lower=True)\n",
    "        gamma = solve_triangular(l, self.gamma)\n",
    "        lam = self.lam-self.dim/2\n",
    "        chi = self.chi+np.sum(z**2, axis=0)\n",
    "        psi = self.psi+np.dot(gamma, gamma)\n",
    "\n",
    "        c = (self.psi/self.chi)**(self.lam/2)/(2*np.pi)**(self.dim/2)/ \\\n",
    "            np.prod(np.diag(l))/kv(self.lam, np.sqrt(self.chi*self.psi) + 0.0j).real\n",
    "        p = c*kv(lam, np.sqrt(chi*psi))*np.exp(np.dot(z.T, gamma))* \\\n",
    "            np.sqrt(psi/chi)**(self.dim/2-self.lam);\n",
    "        return p\n",
    "    \n",
    "    def llh(self, x):\n",
    "        l = np.linalg.cholesky(self.sigma)\n",
    "        z = solve_triangular(l, (x-self.mu).T, lower=True)\n",
    "        gamma = solve_triangular(l, self.gamma)\n",
    "        lam = self.lam-self.dim/2\n",
    "        chi = self.chi+np.sum(z**2, axis=0)\n",
    "        psi = self.psi+np.dot(gamma, gamma)\n",
    "        \n",
    "        delta = np.sqrt(chi/psi)\n",
    "        eta = np.sqrt(chi*psi)\n",
    "        \n",
    "        llh = self.lam/2*np.log(self.psi/self.chi) \\\n",
    "            - logkv(self.lam, np.sqrt(self.chi*self.psi)) \\\n",
    "            + logkv(lam, eta) + np.dot(z.T, gamma) + lam*np.log(delta)\n",
    "        return llh, lam, delta, eta\n",
    "        \n",
    "    \n",
    "    def mean(self):\n",
    "        return self.mu+self.gamma*GIG(self.lam, self.chi, self.psi).mean()\n",
    "    \n",
    "    def cov(self):\n",
    "        gig = GIG(self.lam, self.chi, self.psi)\n",
    "        return self.sigma*gig.mean() + np.outer(self.gamma, self.gamma)*gig.var()\n",
    "    \n",
    "    def fit_em(self, x, max_iter=100, fix_tail=False, eps=1e-5, reg='|sigma|=1', diff=1e-8, disp=True):\n",
    "        if self.dim != x.shape[1]:\n",
    "            raise ValueError('x dimension must be (, {})'.format(self.dim))\n",
    "            \n",
    "        suff_stats = [0]*6\n",
    "        suff_stats[3] = np.mean(x, axis=0)\n",
    "        \n",
    "        llh_last = 0\n",
    "        for i in range(max_iter):\n",
    "            # self.regulate(reg)\n",
    "            llh, lam, delta, eta = self.llh(x)\n",
    "                \n",
    "            if i>0:\n",
    "                if disp:\n",
    "                    print('iter=%s, llh=%.5f, change=%.5f'%(i, llh, llh-llh_last))\n",
    "                \n",
    "                if np.abs(llh-llh_last)<eps:\n",
    "                    if disp:\n",
    "                        print('success')\n",
    "                    return True\n",
    "            llh_last = llh\n",
    "        \n",
    "            # E-step\n",
    "            s = kvratio(lam-1, lam, eta)\n",
    "            suff_stats[0] = np.mean(s)\n",
    "            suff_stats[1] = np.mean(kvratio(lam+1, lam, eta))\n",
    "            suff_stats[2] = np.mean((kvratio(lam+diff, lam, eta)-kvratio(lam-diff, lam, eta))/(2*diff))\n",
    "            suff_stats[4] = np.mean(x.T*s, axis=1)\n",
    "            suff_stats[5] = np.dot((x.T*s)/x.shape[0], x)\n",
    "            \n",
    "            if not fix_tail:\n",
    "                gig = GIG(gh.lam, gh.chi, gh.psi)\n",
    "                res = gig.suffstats2param(suff_stats[0], suff_stats[1], suff_stats[2])\n",
    "                if res.success:\n",
    "                    self.lam = gig.lam\n",
    "                    self.chi = gig.chi\n",
    "                    self.psi = gig.psi\n",
    "                \n",
    "            self.mu = (suff_stats[3]-suff_stats[1]*suff_stats[4])/(1-suff_stats[0]*suff_stats[1])\n",
    "            self.gamma = (suff_stats[4]-suff_stats[0]*suff_stats[3])/(1-suff_stats[0]*suff_stats[1])\n",
    "            self.sigma = -np.outer(suff_stats[4], self.mu)\n",
    "            self.sigma = self.sigma + self.sigma.T + suff_stats[5] \\\n",
    "                + suff_stats[0]*np.outer(self.mu, self.mu) \\\n",
    "                - suff_stats[1]*np.outer(self.gamma, self.gamma)\n",
    "            # self.sigma = np.maximum(self.sigma, self.sigma.T)\n",
    "            \n",
    "        if disp:\n",
    "            print('fail to converge')\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def rvs(self, n, n_grids=int(1e5)):\n",
    "        t = GIG(self.lam, self.chi, self.psi).rvs(n, n_grids)\n",
    "        z = np.random.multivariate_normal(np.zeros(self.dim), self.sigma, n)\n",
    "        x = (np.outer(self.gamma, t) + z.T*np.sqrt(t)).T + mu\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def regulate(self, method='|sigma|=1'):\n",
    "        \"\"\" GH parameterization (mu, gamma Sigma, lambda, chi, psi) is not unique, so regulation is needed.\n",
    "        \"\"\"\n",
    "        if method=='chi=1':\n",
    "            self.gamma = self.gamma*self.chi\n",
    "            self.sigma = self.sigma*self.chi\n",
    "            self.psi = self.psi*self.chi\n",
    "            self.chi = 1.0\n",
    "        elif method=='psi=1':\n",
    "            self.gamma = self.gamma/self.psi\n",
    "            self.sigma = self.sigma/self.psi\n",
    "            self.chi = self.chi*self.psi\n",
    "            self.psi = 1.0\n",
    "        elif method=='chi=psi':\n",
    "            self.gamma = self.gamma*np.sqrt(self.chi/self.psi)\n",
    "            self.sigma = self.sigma*np.sqrt(self.chi/self.psi)\n",
    "            self.chi = np.sqrt(self.chi*self.psi)\n",
    "            self.psi = self.chi\n",
    "        elif method=='|sigma|=1':\n",
    "            _, logd = np.linalg.slogdet(self.sigma)\n",
    "            d = np.exp(logd/self.dim)\n",
    "            self.gamma = self.gamma/d\n",
    "            self.sigma = self.sigma/d\n",
    "            self.chi = self.chi*d\n",
    "            self.psi = self.psi/d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.random.randn(10)\n",
    "sigma = np.cov(np.random.randn(10, 20))\n",
    "gamma = np.random.randn(10)\n",
    "lam=0.9\n",
    "chi=0.3\n",
    "psi=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0.65634476,  1.51842634, -0.63371085])\n",
    "sigma= np.array([[0.35646818, 0.10212985, 0.05799233],\n",
    "       [0.10212985, 0.98229971, 0.15375874],\n",
    "       [0.05799233, 0.15375874, 1.41077451]])\n",
    "gamma = np.array([ 2.05705176, -0.04197259,  0.34341511])\n",
    "lam=0.9\n",
    "chi=0.3\n",
    "psi=1.0\n",
    "\n",
    "mu0 = np.zeros(3)\n",
    "sigma0 = np.eye(3)\n",
    "gamma0 = np.zeros(3)\n",
    "lam0 = 1.0\n",
    "chi0 = 1.0\n",
    "psi0 = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6949953239248218e-16 4.096647724127068e-16\n",
      "2.102382951329647e-17 2.0234082797393442e-16\n",
      "0.0 0.0\n",
      "2.102382951329647e-17 3.54598817343108e-17\n"
     ]
    }
   ],
   "source": [
    "gh = GH(mu, gamma, sigma, lam, chi, psi)\n",
    "m = gh.mean()\n",
    "c = gh.cov()\n",
    "for method in ['|sigma|=1', 'chi=1', 'psi=1', 'chi=psi']:\n",
    "    gh = GH(mu, gamma, sigma, lam, chi, psi)\n",
    "    gh.regulate(method)\n",
    "    print(np.linalg.norm(gh.mean()-m)/np.linalg.norm(m), \n",
    "          np.linalg.norm(gh.cov()-c)/np.linalg.norm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01873334180445365 0.04561532070103447\n"
     ]
    }
   ],
   "source": [
    "gh = GH(mu, gamma, sigma, lam, chi, psi)\n",
    "gh.regulate()\n",
    "x = gh.rvs(1000)\n",
    "print(np.linalg.norm(np.mean(x, axis=0)-m)/np.linalg.norm(m), \n",
    "      np.linalg.norm(np.cov(x.T)-c)/np.linalg.norm(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[ 1.74953772,  1.37746568, -1.54835839],\n",
    "       [ 3.76765938,  1.54792901, -0.36846954],\n",
    "       [ 5.70719392,  0.82978642, -2.07754969],\n",
    "       [ 1.95051383,  0.62586649, -0.66932423],\n",
    "       [ 7.93513039,  0.54582224,  0.90509363],\n",
    "       [11.64517463, -0.26257948,  7.62055921],\n",
    "       [ 0.47822655,  2.261273  , -0.68519925],\n",
    "       [14.36924369,  2.9331593 , -0.39317326],\n",
    "       [ 3.06647501,  0.94545944,  0.87562929],\n",
    "       [ 2.36628983,  1.99396013, -0.60114535]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_fit = GH(mu0, gamma0, sigma0, lam0, chi0, psi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ -5.97546882,  -7.6712775 , -10.06072222,  -5.26444143,\n",
       "        -12.17863615, -18.61459174,  -5.5925779 , -19.41641998,\n",
       "         -6.7417916 ,  -6.52647897]),\n",
       " -0.5,\n",
       " array([ 2.89062409,  4.21035761,  6.21102412,  2.37575419,  8.067429  ,\n",
       "        13.95535606,  2.60989544, 14.70486902,  3.47331098,  3.30705009]),\n",
       " array([ 2.89062409,  4.21035761,  6.21102412,  2.37575419,  8.067429  ,\n",
       "        13.95535606,  2.60989544, 14.70486902,  3.47331098,  3.30705009]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gh_fit.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=1, llh=-4.07511, change=5.72913\n",
      "iter=2, llh=-0.59984, change=3.47526\n",
      "iter=3, llh=-2.11217, change=-1.51233\n",
      "iter=4, llh=-2.57087, change=-0.45870\n",
      "iter=5, llh=-2.87619, change=-0.30532\n",
      "iter=6, llh=-3.00005, change=-0.12386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=7, llh=-3.15745, change=-0.15740\n",
      "iter=8, llh=-3.19400, change=-0.03656\n",
      "iter=9, llh=-3.29609, change=-0.10209\n",
      "iter=10, llh=-3.34145, change=-0.04536\n",
      "iter=11, llh=-3.39780, change=-0.05635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=12, llh=-3.42807, change=-0.03026\n",
      "iter=13, llh=-3.48110, change=-0.05303\n",
      "iter=14, llh=-3.49623, change=-0.01514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=15, llh=-3.51029, change=-0.01406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=16, llh=-3.57696, change=-0.06667\n",
      "iter=17, llh=-3.59409, change=-0.01713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=18, llh=-3.61947, change=-0.02537\n",
      "iter=19, llh=-3.64719, change=-0.02773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=20, llh=-3.66577, change=-0.01857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=21, llh=-3.67505, change=-0.00928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=22, llh=-3.69056, change=-0.01551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=23, llh=-3.71613, change=-0.02557\n",
      "iter=24, llh=-3.71479, change=0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=25, llh=-3.73685, change=-0.02206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=26, llh=-3.75535, change=-0.01849\n",
      "iter=27, llh=-3.75546, change=-0.00012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=28, llh=-3.80121, change=-0.04574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=29, llh=-3.78614, change=0.01506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=30, llh=-3.77543, change=0.01071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=31, llh=-3.80587, change=-0.03043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=32, llh=-3.82195, change=-0.01609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n",
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=33, llh=-3.82992, change=-0.00796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xiangshi/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_hessian_update_strategy.py:187: UserWarning: delta_grad == 0.0. Check if the approximated function is linear. If the function is linear better results can be obtained by defining the Hessian as zero instead of using quasi-Newton approximations.\n",
      "  'approximations.', UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-0f2b626ee60b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgh_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_em\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfix_tail\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-de3c720ebae4>\u001b[0m in \u001b[0;36mfit_em\u001b[0;34m(self, x, max_iter, fix_tail, eps, reg, diff, disp)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfix_tail\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mgig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGIG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffstats2param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuff_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/pygh/pygh/gig.py\u001b[0m in \u001b[0;36msuffstats2param\u001b[0;34m(self, s1, s2, s3)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mx0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpsi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mbounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m20.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'trust-constr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    620\u001b[0m         return _minimize_trustregion_constr(fun, x0, args, jac, hess, hessp,\n\u001b[1;32m    621\u001b[0m                                             \u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstraints\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                                             callback=callback, **options)\n\u001b[0m\u001b[1;32m    623\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'dogleg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         return _minimize_dogleg(fun, x0, args, jac, hess,\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/minimize_trustregion_constr.py\u001b[0m in \u001b[0;36m_minimize_trustregion_constr\u001b[0;34m(fun, x0, args, grad, hess, hessp, bounds, constraints, xtol, gtol, barrier_tol, sparse_jacobian, callback, maxiter, verbose, finite_diff_rel_step, initial_constr_penalty, initial_tr_radius, initial_barrier_parameter, initial_barrier_tolerance, factorization_method, disp)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0minitial_barrier_tolerance\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m             \u001b[0minitial_constr_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_tr_radius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m             factorization_method)\n\u001b[0m\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;31m# Status 3 occurs when the callback function requests termination,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/tr_interior_point.py\u001b[0m in \u001b[0;36mtr_interior_point\u001b[0;34m(fun, grad, lagr_hess, n_vars, n_ineq, n_eq, constr, jac, x0, fun0, grad0, constr_ineq0, jac_ineq0, constr_eq0, jac_eq0, stop_criteria, enforce_feasibility, xtol, state, initial_barrier_parameter, initial_tolerance, initial_penalty, initial_trust_radius, factorization_method)\u001b[0m\n\u001b[1;32m    327\u001b[0m             \u001b[0mconstr0_subprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjac0_subprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_criteria\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_penalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrust_radius\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m             factorization_method, trust_lb, trust_ub, subprob.scaling)\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msubprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterminate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/equality_constrained_sqp.py\u001b[0m in \u001b[0;36mequality_constrained_sqp\u001b[0;34m(fun_and_constr, grad_and_jac, lagr_hess, x0, fun0, grad0, constr0, jac0, stop_criteria, state, initial_penalty, initial_trust_radius, factorization_method, trust_lb, trust_ub, scaling)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0;31m# Get projections\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprojections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactorization_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m             \u001b[0;31m# Compute least-square lagrange multipliers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mLS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/projections.py\u001b[0m in \u001b[0;36mprojections\u001b[0;34m(A, method, orth_tol, max_refin, tol)\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AugmentedSystem'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[0mnull_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_space\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 394\u001b[0;31m             \u001b[0;34m=\u001b[0m \u001b[0maugmented_system_projections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morth_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_refin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    395\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"QRFactorization\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0mnull_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleast_squares\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow_space\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/optimize/_trustregion_constr/projections.py\u001b[0m in \u001b[0;36maugmented_system_projections\u001b[0;34m(A, m, n, orth_tol, max_refin, tol)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;34m\"\"\"Return linear operators for matrix A - ``AugmentedSystem``.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;31m# Form augmented system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsc_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;31m# LU factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;31m# TODO: Use a symmetric indefinite factorization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/sparse/construct.py\u001b[0m in \u001b[0;36mbmat\u001b[0;34m(blocks, format, dtype)\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 574\u001b[0;31m                 \u001b[0mA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    575\u001b[0m                 \u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m                 \u001b[0mblock_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/sparse/coo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, arg1, shape, dtype, copy)\u001b[0m\n\u001b[1;32m    170\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mcoo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtocoo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep_learning_course/lib/python3.7/site-packages/scipy/sparse/dia.py\u001b[0m in \u001b[0;36mtocoo\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moffset_inds\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mnum_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[0mcol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset_inds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_offsets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "gh_fit.fit_em(x, fix_tail=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "k = np.arange(1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factorial(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_fit.sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diff = 1e-8\n",
    "reg = '|sigma|=1'\n",
    "\n",
    "suff_stats = [0]*6\n",
    "suff_stats[3] = np.mean(x, axis=0)\n",
    "\n",
    "gh.regulate(reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llh, lam, delta, eta = gh.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = kvratio(lam-1, lam, eta)\n",
    "\n",
    "suff_stats[0] = np.mean(s)\n",
    "suff_stats[1] = np.mean(kvratio(lam+1, lam, eta))\n",
    "suff_stats[2] = np.mean((kvratio(lam+diff, lam, eta)-kvratio(lam-diff, lam, eta))/(2*diff))\n",
    "suff_stats[4] = np.mean(x.T*s, axis=1)\n",
    "suff_stats[5] = np.dot((x.T*s)/x.shape[0], x)\n",
    "suff_stats[5] = np.maximum(suff_stats[5], suff_stats[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = (S4-S2*S5)/(1-S1*S2);\n",
    "    gamma = (S5-S1*S4)/(1-S1*S2);\n",
    "    Sigma = S6-S5*mu'-mu*S5'+S1*(mu*mu')-S2*(gamma*gamma');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self.mu = (suff_stats[3]-suff_stats[1]*suff_stats[4])/(1-suff_stats[0]*suff_stats[1])\n",
    "self.gamma = (suff_stats[4]-suff_stats[0]*suff_stats[3])/(1-suff_stats[0]*suff_stats[1])\n",
    "self.sigma = -np.outer(suff_stats[4], self.mu)\n",
    "self.sigma = self.sigma + self.sigma.T + suff_stats[5] \\\n",
    "    + suff_stats[0]*np.outer(self.mu, self.mu) \\\n",
    "    - suff_stats[1]*np.outer(self.gamma, self.gamma)\n",
    "# self.sigma[5] = np.maximum(self.sigma[5], self.sigma[5].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gig = GIG(gh.lam, gh.chi, gh.psi)\n",
    "res = gig.suffstats2param(suff_stats[0], suff_stats[1], suff_stats[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update = GH(self.mu, self.gamma, self.sigma, gig.lam, gig.chi, gig.psi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update.regulate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh.llh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gh_update.sigma.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(gh_update.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.svd(gh_update.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    gh_univ = GH(mu=gh.mu[[i]], \n",
    "                 sigma=np.array([[np.diag(gh.sigma)[i]]]), \n",
    "                 gamma=gh.gamma[[i]], \n",
    "                 lam=gh.lam, chi=gh.chi, psi=gh.psi)\n",
    "    nbins = 1000\n",
    "    hist, grids = np.histogram(x[:, i], bins=nbins)\n",
    "    dx = grids[1]-grids[0]\n",
    "\n",
    "    xi = (grids[1:]-dx/2).reshape((nbins, 1))\n",
    "    pdf = gh_univ.pdf(xi)*dx\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.step(grids[1:], hist/np.sum(hist))\n",
    "    ax.step(xi, pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(x, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'iter=%s, llh=%.2f, change='%(1, llh, chg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
